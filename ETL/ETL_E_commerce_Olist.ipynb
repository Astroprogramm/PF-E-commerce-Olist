{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDTBldCr-5iM"
      },
      "source": [
        "ETL</br>\n",
        "*Transformation and imputation of data, perform in datasets*\n",
        "\n",
        "Source of datasets: [Brazilian E-Commerce Public Dataset by Olist - Kaggle](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih9D51DU-5iU"
      },
      "source": [
        "Import of necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SM554MSI-5iV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YWrMn2P-5iY"
      },
      "source": [
        "Uploading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVmSzzI8-5iZ"
      },
      "outputs": [],
      "source": [
        "Closed_deals_df = pd.read_csv('https://raw.githubusercontent.com/Astroprogramm/PF-E-commerce-Olist/master/Datasets/olist_closed_deals_dataset.csv')\n",
        "Customers_df = pd.read_csv('https://raw.githubusercontent.com/Astroprogramm/PF-E-commerce-Olist/master/Datasets/olist_customers_dataset.csv')\n",
        "Geolocation_df = pd.read_csv('https://raw.githubusercontent.com/Astroprogramm/PF-E-commerce-Olist/master/Datasets/olist_geolocation_dataset.csv')\n",
        "Marketing_qualif_leads_df = pd.read_csv ('https://raw.githubusercontent.com/Astroprogramm/PF-E-commerce-Olist/master/Datasets/olist_marketing_qualified_leads_dataset.csv')\n",
        "Order_items_df = pd.read_csv('https://raw.githubusercontent.com/Astroprogramm/PF-E-commerce-Olist/master/Datasets/olist_order_items_dataset.csv')\n",
        "Order_payments_df = pd.read_csv('https://raw.githubusercontent.com/Astroprogramm/PF-E-commerce-Olist/master/Datasets/olist_order_payments_dataset.csv')\n",
        "Order_reviews_df = pd.read_csv('https://raw.githubusercontent.com/Astroprogramm/PF-E-commerce-Olist/master/Datasets/olist_order_reviews_dataset.csv')\n",
        "Orders_df = pd.read_csv('https://raw.githubusercontent.com/Astroprogramm/PF-E-commerce-Olist/master/Datasets/olist_orders_dataset.csv')\n",
        "Products_df = pd.read_csv('https://raw.githubusercontent.com/Astroprogramm/PF-E-commerce-Olist/master/Datasets/olist_products_dataset.csv')\n",
        "Sellers_df = pd.read_csv('https://raw.githubusercontent.com/Astroprogramm/PF-E-commerce-Olist/master/Datasets/olist_sellers_dataset.csv')\n",
        "Category_translat_df = pd.read_csv('https://raw.githubusercontent.com/Astroprogramm/PF-E-commerce-Olist/master/Datasets/product_category_name_translation.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0UwB1Bm-5ia"
      },
      "source": [
        "#ETL Closed Deals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfKP-Uf2-5ib"
      },
      "source": [
        "Change the data type in the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8XVHRKF-5ic"
      },
      "outputs": [],
      "source": [
        "Closed_deals_df.mql_id = Closed_deals_df.mql_id.astype('string')\n",
        "Closed_deals_df.seller_id = Closed_deals_df.seller_id.astype('string')\n",
        "Closed_deals_df.sdr_id = Closed_deals_df.sdr_id.astype('string')\n",
        "Closed_deals_df.sr_id = Closed_deals_df.sr_id.astype('string')\n",
        "Closed_deals_df.sdr_id = Closed_deals_df.sdr_id.astype('string')\n",
        "Closed_deals_df.business_segment = Closed_deals_df.business_segment.astype('string')\n",
        "Closed_deals_df.lead_type = Closed_deals_df.lead_type.astype('string')\n",
        "Closed_deals_df.lead_behaviour_profile = Closed_deals_df.lead_behaviour_profile.astype('string')\n",
        "Closed_deals_df.has_company = Closed_deals_df.has_company.astype('string')\n",
        "Closed_deals_df.has_gtin = Closed_deals_df.has_gtin.astype('string')\n",
        "Closed_deals_df.average_stock = Closed_deals_df.average_stock.astype('string')\n",
        "Closed_deals_df.business_type = Closed_deals_df.business_type.astype('string')\n",
        "Closed_deals_df.won_date = pd.to_datetime(Closed_deals_df.won_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXx3Uwp1-5ie"
      },
      "source": [
        "We verify that the changes have been applied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-XVlzmL-5ie",
        "outputId": "b2b4e6fd-6ee8-4556-c799-8d8b33e10341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 842 entries, 0 to 841\n",
            "Data columns (total 14 columns):\n",
            " #   Column                         Non-Null Count  Dtype         \n",
            "---  ------                         --------------  -----         \n",
            " 0   mql_id                         842 non-null    string        \n",
            " 1   seller_id                      842 non-null    string        \n",
            " 2   sdr_id                         842 non-null    string        \n",
            " 3   sr_id                          842 non-null    string        \n",
            " 4   won_date                       842 non-null    datetime64[ns]\n",
            " 5   business_segment               841 non-null    string        \n",
            " 6   lead_type                      836 non-null    string        \n",
            " 7   lead_behaviour_profile         665 non-null    string        \n",
            " 8   has_company                    63 non-null     string        \n",
            " 9   has_gtin                       64 non-null     string        \n",
            " 10  average_stock                  66 non-null     string        \n",
            " 11  business_type                  832 non-null    string        \n",
            " 12  declared_product_catalog_size  69 non-null     float64       \n",
            " 13  declared_monthly_revenue       842 non-null    float64       \n",
            "dtypes: datetime64[ns](1), float64(2), string(11)\n",
            "memory usage: 92.2 KB\n"
          ]
        }
      ],
      "source": [
        "Closed_deals_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI07hiq3-5ig"
      },
      "source": [
        "#ETL Customers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJKihRRn-5ig"
      },
      "source": [
        "Change the data type in the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ4Mr-6j-5ih"
      },
      "outputs": [],
      "source": [
        "Customers_df.customer_id = Customers_df.customer_id.astype('string')\n",
        "Customers_df.customer_unique_id = Customers_df.customer_unique_id.astype('string')\n",
        "Customers_df.customer_city = Customers_df.customer_city.astype('string')\n",
        "Customers_df.customer_state = Customers_df.customer_state.astype('string')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4WKL5R3-5ii"
      },
      "source": [
        "In this dataset there are no missing values, therefore they will not be imputed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20q8pK8e-5ii"
      },
      "source": [
        "We verify that the changes have been applied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og7ARcdq-5ii",
        "outputId": "f77c065a-5182-4ff5-f09d-6366d765378d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99441 entries, 0 to 99440\n",
            "Data columns (total 5 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   customer_id               99441 non-null  string\n",
            " 1   customer_unique_id        99441 non-null  string\n",
            " 2   customer_zip_code_prefix  99441 non-null  int64 \n",
            " 3   customer_city             99441 non-null  string\n",
            " 4   customer_state            99441 non-null  string\n",
            "dtypes: int64(1), string(4)\n",
            "memory usage: 3.8 MB\n"
          ]
        }
      ],
      "source": [
        "Customers_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvx9gl0T-5ij"
      },
      "source": [
        "#ETL GEOLOCATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rby4FzP-5ij"
      },
      "source": [
        "Change the data type in the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF3iaQWy-5ik"
      },
      "outputs": [],
      "source": [
        "Geolocation_df.geolocation_city = Geolocation_df.geolocation_city.astype('string')\n",
        "Geolocation_df.geolocation_state = Geolocation_df.geolocation_state.astype('string')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-utpkCf-5ik"
      },
      "source": [
        "In this dataset there are no missing values, therefore they will not be imputed, but if we have duplicate values, these duplicate values ​​will not be treated due to the quantity and quality of these"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3zd3Q0W-5il"
      },
      "source": [
        "We verify that the changes have been applied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGO95ESD-5il",
        "outputId": "f67c2ae5-cf6e-4ac5-edbd-4ecdfac00166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000163 entries, 0 to 1000162\n",
            "Data columns (total 5 columns):\n",
            " #   Column                       Non-Null Count    Dtype  \n",
            "---  ------                       --------------    -----  \n",
            " 0   geolocation_zip_code_prefix  1000163 non-null  int64  \n",
            " 1   geolocation_lat              1000163 non-null  float64\n",
            " 2   geolocation_lng              1000163 non-null  float64\n",
            " 3   geolocation_city             1000163 non-null  string \n",
            " 4   geolocation_state            1000163 non-null  string \n",
            "dtypes: float64(2), int64(1), string(2)\n",
            "memory usage: 38.2 MB\n"
          ]
        }
      ],
      "source": [
        "Geolocation_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vejV7YJy-5im"
      },
      "source": [
        "#ETL Marketing_qualif_leads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxcCdXy8-5im"
      },
      "source": [
        "Change the data type in the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvHMg4js-5im"
      },
      "outputs": [],
      "source": [
        "Marketing_qualif_leads_df.mql_id = Marketing_qualif_leads_df.mql_id.astype('string')\n",
        "Marketing_qualif_leads_df.landing_page_id = Marketing_qualif_leads_df.landing_page_id.astype('string')\n",
        "Marketing_qualif_leads_df.origin = Marketing_qualif_leads_df.origin.astype('string')\n",
        "Marketing_qualif_leads_df.first_contact_date = pd.to_datetime(Marketing_qualif_leads_df.first_contact_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNgWO5IO-5in"
      },
      "source": [
        "We verify that the changes have been applied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkPsc9_N-5in",
        "outputId": "a38b1254-43e5-4410-c583-f2f98e6d1b25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8000 entries, 0 to 7999\n",
            "Data columns (total 4 columns):\n",
            " #   Column              Non-Null Count  Dtype         \n",
            "---  ------              --------------  -----         \n",
            " 0   mql_id              8000 non-null   string        \n",
            " 1   first_contact_date  8000 non-null   datetime64[ns]\n",
            " 2   landing_page_id     8000 non-null   string        \n",
            " 3   origin              7940 non-null   string        \n",
            "dtypes: datetime64[ns](1), string(3)\n",
            "memory usage: 250.1 KB\n"
          ]
        }
      ],
      "source": [
        "Marketing_qualif_leads_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiCrP306-5in"
      },
      "source": [
        "#ETL Order items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AzD1MMX-5io"
      },
      "source": [
        "Change the data type in the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6osFCjFZ-5io"
      },
      "outputs": [],
      "source": [
        "Order_items_df.order_id = Order_items_df.order_id.astype('string')\n",
        "Order_items_df.product_id = Order_items_df.product_id.astype('string')\n",
        "Order_items_df.seller_id = Order_items_df.seller_id.astype('string')\n",
        "Order_items_df.shipping_limit_date = pd.to_datetime(Order_items_df.shipping_limit_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2mJA0gO-5io"
      },
      "source": [
        "In this dataset there are no missing values, therefore they will not be imputed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTG4rIvM-5ip"
      },
      "source": [
        "We verify that the changes have been applied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrZJxq64-5ip",
        "outputId": "852145a0-ab6e-4660-e36f-4cf26038e56d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 112650 entries, 0 to 112649\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count   Dtype         \n",
            "---  ------               --------------   -----         \n",
            " 0   order_id             112650 non-null  string        \n",
            " 1   order_item_id        112650 non-null  int64         \n",
            " 2   product_id           112650 non-null  string        \n",
            " 3   seller_id            112650 non-null  string        \n",
            " 4   shipping_limit_date  112650 non-null  datetime64[ns]\n",
            " 5   price                112650 non-null  float64       \n",
            " 6   freight_value        112650 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(2), int64(1), string(3)\n",
            "memory usage: 6.0 MB\n"
          ]
        }
      ],
      "source": [
        "Order_items_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8Brbg9p-5ip"
      },
      "source": [
        "#ETL Order Payments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzSXmyTF-5iq"
      },
      "source": [
        "Change the data type in the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHocXag2-5iq"
      },
      "outputs": [],
      "source": [
        "Order_payments_df.order_id = Order_payments_df.order_id.astype('string')\n",
        "Order_payments_df.payment_type = Order_payments_df.payment_type.astype('string')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8404irp-5iq"
      },
      "source": [
        "In this dataset there are no missing values, therefore they will not be imputed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qh0LzV8-5ir"
      },
      "source": [
        "We verify that the changes have been applied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59F2wtkY-5ir",
        "outputId": "d43ebdd3-1b2b-4933-c85e-32dadcfe7685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 103886 entries, 0 to 103885\n",
            "Data columns (total 5 columns):\n",
            " #   Column                Non-Null Count   Dtype  \n",
            "---  ------                --------------   -----  \n",
            " 0   order_id              103886 non-null  string \n",
            " 1   payment_sequential    103886 non-null  int64  \n",
            " 2   payment_type          103886 non-null  string \n",
            " 3   payment_installments  103886 non-null  int64  \n",
            " 4   payment_value         103886 non-null  float64\n",
            "dtypes: float64(1), int64(2), string(2)\n",
            "memory usage: 4.0 MB\n"
          ]
        }
      ],
      "source": [
        "Order_payments_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjvTVggu-5is"
      },
      "source": [
        "#ETL Order Reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4LK0whI-5is"
      },
      "source": [
        "Change the data type in the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVP9HtTH-5is"
      },
      "outputs": [],
      "source": [
        "Order_reviews_df.review_id = Order_reviews_df.review_id.astype('string')\n",
        "Order_reviews_df.order_id = Order_reviews_df.order_id.astype('string')\n",
        "Order_reviews_df.review_comment_title = Order_reviews_df.review_comment_title.astype('string')\n",
        "Order_reviews_df.review_comment_message = Order_reviews_df.review_comment_message.astype('string')\n",
        "Order_reviews_df.review_creation_date = pd.to_datetime(Order_reviews_df.review_creation_date)\n",
        "Order_reviews_df.review_answer_timestamp = pd.to_datetime(Order_reviews_df.review_answer_timestamp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpHXGCBs-5is"
      },
      "source": [
        "We verify that the changes have been applied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SO34M3z-5it",
        "outputId": "93289850-071b-4b28-bee2-f95d17b77dca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99224 entries, 0 to 99223\n",
            "Data columns (total 7 columns):\n",
            " #   Column                   Non-Null Count  Dtype         \n",
            "---  ------                   --------------  -----         \n",
            " 0   review_id                99224 non-null  string        \n",
            " 1   order_id                 99224 non-null  string        \n",
            " 2   review_score             99224 non-null  int64         \n",
            " 3   review_comment_title     11568 non-null  string        \n",
            " 4   review_comment_message   40977 non-null  string        \n",
            " 5   review_creation_date     99224 non-null  datetime64[ns]\n",
            " 6   review_answer_timestamp  99224 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](2), int64(1), string(4)\n",
            "memory usage: 5.3 MB\n"
          ]
        }
      ],
      "source": [
        "Order_reviews_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq2KQIs0-5it"
      },
      "source": [
        "#ETL Orders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR9szWPF-5it"
      },
      "source": [
        "Change the data type in the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaMsKT-5-5iu"
      },
      "outputs": [],
      "source": [
        "Orders_df.customer_id = Orders_df.customer_id.astype('string')\n",
        "Orders_df.order_id = Orders_df.order_id.astype('string')\n",
        "Orders_df.order_status = Orders_df.order_status.astype('string')\n",
        "Orders_df.order_purchase_timestamp = pd.to_datetime(Orders_df.order_purchase_timestamp)\n",
        "Orders_df.order_approved_at = pd.to_datetime(Orders_df.order_approved_at)\n",
        "Orders_df.order_delivered_carrier_date = pd.to_datetime(Orders_df.order_delivered_carrier_date)\n",
        "Orders_df.order_delivered_customer_date = pd.to_datetime(Orders_df.order_delivered_customer_date)\n",
        "Orders_df.order_estimated_delivery_date = pd.to_datetime(Orders_df.order_estimated_delivery_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwF-pFdX-5iu"
      },
      "source": [
        "We verify that the changes have been applied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XxSxDaw-5iu",
        "outputId": "6a48ad0a-82a7-4b2e-d976-e0376ad5f7d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99441 entries, 0 to 99440\n",
            "Data columns (total 8 columns):\n",
            " #   Column                         Non-Null Count  Dtype         \n",
            "---  ------                         --------------  -----         \n",
            " 0   order_id                       99441 non-null  string        \n",
            " 1   customer_id                    99441 non-null  string        \n",
            " 2   order_status                   99441 non-null  string        \n",
            " 3   order_purchase_timestamp       99441 non-null  datetime64[ns]\n",
            " 4   order_approved_at              99281 non-null  datetime64[ns]\n",
            " 5   order_delivered_carrier_date   97658 non-null  datetime64[ns]\n",
            " 6   order_delivered_customer_date  96476 non-null  datetime64[ns]\n",
            " 7   order_estimated_delivery_date  99441 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](5), string(3)\n",
            "memory usage: 6.1 MB\n"
          ]
        }
      ],
      "source": [
        "Orders_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZJEY_u5-5iv"
      },
      "source": [
        "#ETL Products"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTF5FSoZ-5iv"
      },
      "source": [
        "Change the data type in the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmktsitP-5iw"
      },
      "outputs": [],
      "source": [
        "Products_df.product_id = Products_df.product_id.astype('string')\n",
        "Products_df.product_category_name = Products_df.product_category_name.astype('string')\n",
        "Products_df.product_name_lenght = Products_df.product_name_lenght.astype('float')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CRVwzRS-5iw"
      },
      "source": [
        "We verify that the changes have been applied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9A9UlLC-5iw",
        "outputId": "22f48a79-71a7-49e9-9f50-9e4d28f3a9ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 32951 entries, 0 to 32950\n",
            "Data columns (total 9 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   product_id                  32951 non-null  string \n",
            " 1   product_category_name       32341 non-null  string \n",
            " 2   product_name_lenght         32341 non-null  float64\n",
            " 3   product_description_lenght  32341 non-null  float64\n",
            " 4   product_photos_qty          32341 non-null  float64\n",
            " 5   product_weight_g            32949 non-null  float64\n",
            " 6   product_length_cm           32949 non-null  float64\n",
            " 7   product_height_cm           32949 non-null  float64\n",
            " 8   product_width_cm            32949 non-null  float64\n",
            "dtypes: float64(7), string(2)\n",
            "memory usage: 2.3 MB\n"
          ]
        }
      ],
      "source": [
        "Products_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_1yiXR3-5ix"
      },
      "source": [
        "#ETL Sellers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvDWE6yJ-5ix"
      },
      "source": [
        "Change the data type in the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "262oB61Z-5iy"
      },
      "outputs": [],
      "source": [
        "Sellers_df.seller_id = Sellers_df.seller_id.astype('string')\n",
        "Sellers_df.seller_city = Sellers_df.seller_city.astype('string')\n",
        "Sellers_df.seller_state= Sellers_df.seller_state.astype('string')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0JrqkAE-5iy"
      },
      "source": [
        "In this dataset there are no missing values, therefore they will not be imputed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlENfHT0-5iy"
      },
      "source": [
        "We verify that the changes have been applied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KihcX7nz-5iz",
        "outputId": "225ca241-730c-4dce-b785-2b2741ad270e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3095 entries, 0 to 3094\n",
            "Data columns (total 4 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   seller_id               3095 non-null   string\n",
            " 1   seller_zip_code_prefix  3095 non-null   int64 \n",
            " 2   seller_city             3095 non-null   string\n",
            " 3   seller_state            3095 non-null   string\n",
            "dtypes: int64(1), string(3)\n",
            "memory usage: 96.8 KB\n"
          ]
        }
      ],
      "source": [
        "Sellers_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_GkMF7S-5iz"
      },
      "source": [
        "#ETL Category_translat_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQH0T-QO-5i0"
      },
      "source": [
        "Change the data type in the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt93wfGr-5i0"
      },
      "outputs": [],
      "source": [
        "Category_translat_df.product_category_name = Category_translat_df.product_category_name.astype('string')\n",
        "Category_translat_df.product_category_name_english = Category_translat_df.product_category_name_english.astype('string')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6SN0EFM-5i0"
      },
      "source": [
        "In this dataset there are no missing values, therefore they will not be imputed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpLHeF4p-5i0"
      },
      "source": [
        "We verify that the changes have been applied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5RGCaJF-5i0",
        "outputId": "0e327a73-87cb-40d6-eeea-3ae42ad12877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 71 entries, 0 to 70\n",
            "Data columns (total 2 columns):\n",
            " #   Column                         Non-Null Count  Dtype \n",
            "---  ------                         --------------  ----- \n",
            " 0   product_category_name          71 non-null     string\n",
            " 1   product_category_name_english  71 non-null     string\n",
            "dtypes: string(2)\n",
            "memory usage: 1.2 KB\n"
          ]
        }
      ],
      "source": [
        "Category_translat_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imputing null values"
      ],
      "metadata": {
        "id": "kNxHhFzOCrK2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1FpbKxv-5i1"
      },
      "source": [
        "To impute null values ​​we create a function that imputes null values ​​depending on the type of data in the columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZDO_sir-5i1"
      },
      "source": [
        "We store in a list all the dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inzrWPKv-5i1"
      },
      "outputs": [],
      "source": [
        "datasets_names= [Closed_deals_df,Marketing_qualif_leads_df,Order_reviews_df,Orders_df,Products_df]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtUSf6sl-5i2"
      },
      "source": [
        "We create the function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXR9XID7-5i2"
      },
      "outputs": [],
      "source": [
        "def ImputeNulls(datasets_names):\n",
        "    for dataset in datasets_names:\n",
        "        for column in dataset.columns:\n",
        "            #Null imputation in strings\n",
        "            if dataset[column].dtype == 'string[python]':\n",
        "                if dataset[column].isnull().sum() >=1:\n",
        "                    dataset[column].fillna('No data', inplace=True)\n",
        "            #Null imputation in float64:\n",
        "            elif dataset[column].dtype == 'float64':\n",
        "                if dataset[column].isnull().sum() >=1:\n",
        "                    dataset[column].fillna(0, inplace=True)\n",
        "            #Null imputation in int64:\n",
        "            elif dataset[column].dtype == 'int64':\n",
        "                if dataset[column].isnull().sum() >=1:\n",
        "                    dataset[column].fillna(0, inplace=True)\n",
        "            #Null imputation in datetime\n",
        "            elif dataset[column].dtype == 'datetime64[ns]':\n",
        "                if dataset[column].isnull().sum() >=1:\n",
        "                    dataset[column].fillna('No data', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGAQ4j9c-5i2"
      },
      "source": [
        "We carry out the imputation of nulls by means of the function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TygEzDS7-5i2"
      },
      "outputs": [],
      "source": [
        "ImputeNulls(datasets_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnM3pbPj-5i3"
      },
      "source": [
        "We verify that the changes have been applied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d_Nod8J-5i3",
        "outputId": "af69c439-3c0f-4b9a-92ad-52de5e452abe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "mql_id                           0\n",
              "seller_id                        0\n",
              "sdr_id                           0\n",
              "sr_id                            0\n",
              "won_date                         0\n",
              "business_segment                 0\n",
              "lead_type                        0\n",
              "lead_behaviour_profile           0\n",
              "has_company                      0\n",
              "has_gtin                         0\n",
              "average_stock                    0\n",
              "business_type                    0\n",
              "declared_product_catalog_size    0\n",
              "declared_monthly_revenue         0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Closed_deals_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XshG1nb6-5i3",
        "outputId": "ccfd9d5d-9716-4a6d-e505-1e4469015c50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "mql_id                0\n",
              "first_contact_date    0\n",
              "landing_page_id       0\n",
              "origin                0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Marketing_qualif_leads_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9SV9cec-5i4",
        "outputId": "e688ea96-347d-4b0a-9d6b-090c3aa16907"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "review_id                  0\n",
              "order_id                   0\n",
              "review_score               0\n",
              "review_comment_title       0\n",
              "review_comment_message     0\n",
              "review_creation_date       0\n",
              "review_answer_timestamp    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Order_reviews_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEZ8xHyZ-5i4",
        "outputId": "3b35557b-fd32-4086-acaa-6faf3c428eb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "order_id                         0\n",
              "customer_id                      0\n",
              "order_status                     0\n",
              "order_purchase_timestamp         0\n",
              "order_approved_at                0\n",
              "order_delivered_carrier_date     0\n",
              "order_delivered_customer_date    0\n",
              "order_estimated_delivery_date    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Orders_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uedgwfsg-5i4",
        "outputId": "bb1f85bb-912f-4067-dc66-346b9364dca9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "product_id                    0\n",
              "product_category_name         0\n",
              "product_name_lenght           0\n",
              "product_description_lenght    0\n",
              "product_photos_qty            0\n",
              "product_weight_g              0\n",
              "product_length_cm             0\n",
              "product_height_cm             0\n",
              "product_width_cm              0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Products_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Division of datasets to test incremental upload"
      ],
      "metadata": {
        "id": "FGabuErlC3hW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2ULVPXU-5i5"
      },
      "source": [
        "We split the dataset into two parts, one for the initial data load and one for the incremental load in the data warehouse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbm-ALG6-5i6"
      },
      "source": [
        "Closed_deals_df Division"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyWUxp59-5i6",
        "outputId": "29d9f8ba-a907-4c1f-d9bc-c2d04d192d18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****CLOSED DEALS*****\n",
            "Datos usados para la carga inicial:  589\n",
            "Datos usados para la carga incremental 253\n"
          ]
        }
      ],
      "source": [
        "Closed_deals_inicial, Closed_deals_Incremental = train_test_split(Closed_deals_df, test_size = 0.30, shuffle = False)\n",
        "print(\"*****CLOSED DEALS*****\")\n",
        "print(\"Datos usados para la carga inicial: \", len(Closed_deals_inicial))\n",
        "print(\"Datos usados para la carga incremental\", len(Closed_deals_Incremental))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsKianMt-5i6"
      },
      "source": [
        "Customers division"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nC53HohQ-5i7",
        "outputId": "2af14136-ecef-44c3-99d7-0eb2116810ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****CUSTOMERS*****\n",
            "Datos usados para la carga inicial:  69608\n",
            "Datos usados para la carga incremental 29833\n"
          ]
        }
      ],
      "source": [
        "Customers_inicial, Customers_Incremental = train_test_split(Customers_df, test_size = 0.30, shuffle = False)\n",
        "print(\"*****CUSTOMERS*****\")\n",
        "print(\"Datos usados para la carga inicial: \", len(Customers_inicial))\n",
        "print(\"Datos usados para la carga incremental\", len(Customers_Incremental))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0blCPH1-5i7"
      },
      "source": [
        "Geolocation division"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PebQAGdN-5i7",
        "outputId": "0adea581-1343-4c6f-e9c1-53bf1640f623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****CUSTOMERS*****\n",
            "Datos usados para la carga inicial:  700114\n",
            "Datos usados para la carga incremental 300049\n"
          ]
        }
      ],
      "source": [
        "Geolocation_inicial, Geolocation_Incremental = train_test_split(Geolocation_df, test_size = 0.30, shuffle = False)\n",
        "print(\"*****GEOLOCATION*****\")\n",
        "print(\"Datos usados para la carga inicial: \", len(Geolocation_inicial))\n",
        "print(\"Datos usados para la carga incremental\", len(Geolocation_Incremental))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXiFZn6m-5i8"
      },
      "source": [
        "Marketing_qualif_leads division"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnuO5RhF-5i8",
        "outputId": "9738c29e-11d3-405f-de05-b5c0ac5e65ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****MARQUETING QUIALIF LEADS*****\n",
            "Datos usados para la carga inicial:  5600\n",
            "Datos usados para la carga incremental 2400\n"
          ]
        }
      ],
      "source": [
        "Marqueting_inicial, Marqueting_Incremental = train_test_split(Marketing_qualif_leads_df, test_size = 0.30, shuffle = False)\n",
        "print(\"*****MARQUETING QUIALIF LEADS*****\")\n",
        "print(\"Datos usados para la carga inicial: \", len(Marqueting_inicial))\n",
        "print(\"Datos usados para la carga incremental\", len(Marqueting_Incremental))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W19p6jUx-5i8"
      },
      "source": [
        "Order_items division"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_aCCWRV-5i9",
        "outputId": "36aa9376-31fe-4b87-84bc-b51b3f1ec184"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****ORDER ITEMS*****\n",
            "Datos usados para la carga inicial:  78855\n",
            "Datos usados para la carga incremental 33795\n"
          ]
        }
      ],
      "source": [
        "Order_items_inicial, Order_items_Incremental = train_test_split(Order_items_df, test_size = 0.30, shuffle = False)\n",
        "print(\"*****ORDER ITEMS*****\")\n",
        "print(\"Datos usados para la carga inicial: \", len(Order_items_inicial))\n",
        "print(\"Datos usados para la carga incremental\", len(Order_items_Incremental))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN_TD2eW-5i9"
      },
      "source": [
        "Order Payments division"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6RcAZUU-5i9",
        "outputId": "92505c82-0c2b-4d19-ae40-959690252083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****ORDER PAYMENTS*****\n",
            "Datos usados para la carga inicial:  72720\n",
            "Datos usados para la carga incremental 31166\n"
          ]
        }
      ],
      "source": [
        "Order_payments_inicial, Order_payments_Incremental = train_test_split(Order_payments_df, test_size = 0.30, shuffle = False)\n",
        "print(\"*****ORDER PAYMENTS*****\")\n",
        "print(\"Datos usados para la carga inicial: \", len(Order_payments_inicial))\n",
        "print(\"Datos usados para la carga incremental\", len(Order_payments_Incremental))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYtmvVfN-5i9"
      },
      "source": [
        "Order Reviews division"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFgaeXjd-5i-",
        "outputId": "75208b4c-b2a2-46b3-8faf-9b76259be6a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****ORDER REVIEWS*****\n",
            "Datos usados para la carga inicial:  69456\n",
            "Datos usados para la carga incremental 29768\n"
          ]
        }
      ],
      "source": [
        "Order_reviews_inicial, Order_reviews_Incremental = train_test_split(Order_reviews_df, test_size = 0.30, shuffle = False)\n",
        "print(\"*****ORDER REVIEWS*****\")\n",
        "print(\"Datos usados para la carga inicial: \", len(Order_reviews_inicial))\n",
        "print(\"Datos usados para la carga incremental\", len(Order_reviews_Incremental))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgE4hndl-5i-"
      },
      "source": [
        "Orders division"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9hARSg8-5i-",
        "outputId": "61ada9b0-d5eb-4ae3-eb69-3db6cc438259"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****ORDERS*****\n",
            "Datos usados para la carga inicial:  69608\n",
            "Datos usados para la carga incremental 29833\n"
          ]
        }
      ],
      "source": [
        "Orders_inicial, Orders_Incremental = train_test_split(Orders_df, test_size = 0.30, shuffle = False)\n",
        "print(\"*****ORDERS*****\")\n",
        "print(\"Datos usados para la carga inicial: \", len(Orders_inicial))\n",
        "print(\"Datos usados para la carga incremental\", len(Orders_Incremental))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOY4oEY--5i_"
      },
      "source": [
        "Products division"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAQZuUE5-5i_",
        "outputId": "0b0118f8-a8cc-4235-c3f6-09e1b302644b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****PRODUCTS*****\n",
            "Datos usados para la carga inicial:  23065\n",
            "Datos usados para la carga incremental 9886\n"
          ]
        }
      ],
      "source": [
        "Products_inicial, Products_Incremental = train_test_split(Products_df, test_size = 0.30, shuffle = False)\n",
        "print(\"*****PRODUCTS*****\")\n",
        "print(\"Datos usados para la carga inicial: \", len(Products_inicial))\n",
        "print(\"Datos usados para la carga incremental\", len(Products_Incremental))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3iVpy7_-5jA"
      },
      "source": [
        "Sellers division"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84IbGM5s-5jA",
        "outputId": "161f7c63-54e6-439d-d3ff-0eac285b7b2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****SELLERS*****\n",
            "Datos usados para la carga inicial:  2166\n",
            "Datos usados para la carga incremental 929\n"
          ]
        }
      ],
      "source": [
        "Sellers_inicial, Sellers_Incremental = train_test_split(Sellers_df, test_size = 0.30, shuffle = False)\n",
        "print(\"*****SELLERS*****\")\n",
        "print(\"Datos usados para la carga inicial: \", len(Sellers_inicial))\n",
        "print(\"Datos usados para la carga incremental\", len(Sellers_Incremental))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7U8fSN--5jA"
      },
      "source": [
        "Category translat division"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWauHr-6-5jB",
        "outputId": "a90884ba-c93c-459f-d4b8-85a7c437e3ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****CATEGORY TRANSLAT*****\n",
            "Datos usados para la carga inicial:  49\n",
            "Datos usados para la carga incremental 22\n"
          ]
        }
      ],
      "source": [
        "Category_translat_inicial, Category_translat_Incremental = train_test_split(Category_translat_df, test_size = 0.30, shuffle = False)\n",
        "print(\"*****CATEGORY TRANSLAT*****\")\n",
        "print(\"Datos usados para la carga inicial: \", len(Category_translat_inicial))\n",
        "print(\"Datos usados para la carga incremental\", len(Category_translat_Incremental))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initial load"
      ],
      "metadata": {
        "id": "pzu3yvSJDE08"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c3Xe2aC-5jB"
      },
      "source": [
        "We have already finished the ETL.</br>\n",
        "Our next step will be to carry out the initial load to our Data Warehouse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OsF0-kU-5jC"
      },
      "source": [
        "We are going to load the original dataset with SQLALCHEMY in our Data Warehouse, this would be our initial load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPyQUuw3-5jC"
      },
      "outputs": [],
      "source": [
        "import pymysql\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "cadena_conexion = 'mysql+pymysql://root:root@localhost:3306/ecommerceolist' #Create the connection string that will be the path of our database\n",
        "\n",
        "conexion= create_engine(cadena_conexion) # create the connection with MySQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3ft1NDr-5jC"
      },
      "source": [
        "Load the dataframes in Mysql table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPNNYH6f-5jC"
      },
      "outputs": [],
      "source": [
        "Closed_deals_inicial.to_sql(name='Closed_deals', con=conexion, index=False)\n",
        "Customers_inicial.to_sql(name='Customers', con=conexion, index=False)\n",
        "Geolocation_inicial.to_sql(name='Geolocation', con=conexion, index=False)\n",
        "Marqueting_inicial.to_sql(name='Marketing_qualif_leads', con=conexion, index=False)\n",
        "Order_items_inicial.to_sql(name='Order_items', con=conexion, index=False)\n",
        "Order_payments_Incremental.to_sql(name='Order_payments', con=conexion, index=False)\n",
        "Order_reviews_inicial.to_sql(name='Order_reviews', con=conexion, index=False)\n",
        "Orders_inicial.to_sql(name='Orders', con=conexion, index=False)\n",
        "Products_inicial.to_sql(name='Products', con=conexion, index=False)\n",
        "Sellers_inicial.to_sql(name='Sellers', con=conexion, index=False)\n",
        "Category_translat_inicial.to_sql(name='Category_translat', con=conexion, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Incremental load"
      ],
      "metadata": {
        "id": "Z5zd4uL8JvTL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaDzXudyJRqF"
      },
      "source": [
        "Next step: incremental load in our Data Warehouse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMN_fu42JRqF"
      },
      "source": [
        "We create and establish the connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w0m8viGJRqG"
      },
      "outputs": [],
      "source": [
        "import pymysql\n",
        "conexion = pymysql.connect(\n",
        "   host='34.176.180.147',\n",
        "   database='ecommerceolist',\n",
        "   user='root',\n",
        "   password='olist'\n",
        ")#create engine\n",
        "cursor = conexion.cursor()#create cursor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEbANPLaJRqG"
      },
      "source": [
        "We test the connection with Mysql showing the data Warehouse tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kgjLJZXJRqH",
        "outputId": "4be5fe09-2744-41ed-8f5f-ee08de0b2f09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Category_translat',)\n",
            "('Closed_deals',)\n",
            "('Customers',)\n",
            "('Geolocation',)\n",
            "('Marketing_qualif_leads',)\n",
            "('Order_items',)\n",
            "('Order_payments',)\n",
            "('Order_reviews',)\n",
            "('Orders',)\n",
            "('Products',)\n",
            "('Sellers',)\n",
            "('audit_category_translat',)\n",
            "('audit_closed_deals',)\n",
            "('audit_customers',)\n",
            "('audit_geolocation',)\n",
            "('audit_marketing_qualif',)\n",
            "('audit_order',)\n",
            "('audit_order_items',)\n",
            "('audit_order_payments',)\n",
            "('audit_order_reviews',)\n",
            "('audit_products',)\n",
            "('audit_sellers',)\n"
          ]
        }
      ],
      "source": [
        "cursor=conexion.cursor()\n",
        "cursor.execute(\"show tables\")\n",
        "for tabla in cursor:\n",
        "    print(tabla)\n",
        "conexion.close()  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK3qzttsJRqH"
      },
      "source": [
        "The connection works perfectly. ¡We start with incremental loading!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kPeMvhDJRqH"
      },
      "source": [
        "Incremental load closed deals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGdVbazRJRqI"
      },
      "outputs": [],
      "source": [
        "sql = \"\"\"\n",
        "INSERT INTO ecommerceolist.Closed_deals\n",
        "(mql_id, seller_id, sdr_id, sr_id, won_date, business_segment, lead_type, lead_behaviour_profile, has_company, has_gtin, average_stock, business_type,declared_product_catalog_size,declared_monthly_revenue)\n",
        "VALUES (%s, %s,%s, %s,%s, %s,%s, %s,%s, %s,%s, %s,%s, %s)\n",
        "\"\"\"\n",
        "registros = []\n",
        "for index, row in Closed_deals_Incremental.iterrows():\n",
        "    registros.append( \n",
        "        (\n",
        "            row['mql_id'], \n",
        "            row['seller_id'], \n",
        "            row['sdr_id'], \n",
        "            row['sr_id'],\n",
        "            row['won_date'],\n",
        "            row['business_segment'],\n",
        "            row['lead_type'],\n",
        "            row['lead_behaviour_profile'],\n",
        "            row['has_company'],\n",
        "            row['has_gtin'],\n",
        "            row['average_stock'],\n",
        "            row['business_type'],\n",
        "            row['declared_product_catalog_size'], \n",
        "            row['declared_monthly_revenue']\n",
        "            ))\n",
        "\n",
        "cursor.executemany(sql, registros)\n",
        "conexion.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8uhedc1JRqJ"
      },
      "source": [
        "Incremental load Customers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxWVnNwkJRqK"
      },
      "outputs": [],
      "source": [
        "sql = \"\"\"\n",
        "INSERT INTO ecommerceolist.Customers\n",
        "(customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state) \n",
        "VALUES (%s, %s,%s, %s,%s)\n",
        "\"\"\"\n",
        "registros = []\n",
        "for index, row in Customers_Incremental.iterrows():\n",
        "    registros.append( \n",
        "        (\n",
        "            row['customer_id'], \n",
        "            row['customer_unique_id'], \n",
        "            row['customer_zip_code_prefix'], \n",
        "            row['customer_city'],\n",
        "            row['customer_state']\n",
        "            ))\n",
        "\n",
        "cursor.executemany(sql, registros)\n",
        "conexion.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znQ_u0maJRqL"
      },
      "source": [
        "Incremental load Geolocation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYce1lp0JRqM"
      },
      "outputs": [],
      "source": [
        "sql = \"\"\"\n",
        "INSERT INTO ecommerceolist.Geolocation(geolocation_zip_code_prefix, geolocation_lat, geolocation_lng, geolocation_city, geolocation_state) \n",
        "VALUES (%s, %s,%s, %s,%s)\n",
        "\"\"\"\n",
        "registros = []\n",
        "for index, row in Geolocation_Incremental.iterrows():\n",
        "    registros.append( \n",
        "        (\n",
        "            row['geolocation_zip_code_prefix'], \n",
        "            row['geolocation_lat'], \n",
        "            row['geolocation_lng'], \n",
        "            row['geolocation_city'],\n",
        "            row['geolocation_state']\n",
        "            ))\n",
        "\n",
        "cursor.executemany(sql, registros)\n",
        "conexion.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty94efxtJRqM"
      },
      "source": [
        "Incremental load Marketing qualif leads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzMZJO7JJRqM"
      },
      "outputs": [],
      "source": [
        "sql = \"\"\"\n",
        "INSERT INTO ecommerceolist.Marketing_qualif_leads(mql_id, first_contact_date,landing_page_id, origin) \n",
        "VALUES (%s, %s,%s, %s)\n",
        "\"\"\"\n",
        "registros = []\n",
        "for index, row in Marqueting_Incremental.iterrows():\n",
        "    registros.append( \n",
        "        (\n",
        "            row['mql_id'], \n",
        "            row['first_contact_date'], \n",
        "            row['landing_page_id'], \n",
        "            row['origin']\n",
        "            ))\n",
        "\n",
        "cursor.executemany(sql, registros)\n",
        "conexion.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyguJ0RPJRqN"
      },
      "source": [
        "Incremental load Order items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv0NFzfjJRqN"
      },
      "outputs": [],
      "source": [
        "sql = \"\"\"\n",
        "INSERT INTO ecommerceolist.Order_items(order_id, order_item_id, product_id, seller_id, shipping_limit_date, price, freight_value) \n",
        "values (%s, %s, %s, %s, %s, %s, %s)\n",
        "\"\"\"\n",
        "registros = []\n",
        "for index, row in Order_items_Incremental.iterrows():\n",
        "    registros.append( \n",
        "        (\n",
        "            row['order_id'], \n",
        "            row['order_item_id'], \n",
        "            row['product_id'], \n",
        "            row['seller_id'],\n",
        "            row['shipping_limit_date'],\n",
        "            row['price'],\n",
        "            row['freight_value']\n",
        "            ))\n",
        "\n",
        "cursor.executemany(sql, registros)\n",
        "conexion.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKwF9yd9JRqO"
      },
      "source": [
        "Incremental load Order Payments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBDPL1cOJRqO"
      },
      "outputs": [],
      "source": [
        "sql = \"\"\"\n",
        "INSERT INTO ecommerceolist.Order_payments(order_id, payment_sequential, payment_type, payment_installments, payment_value) \n",
        "VALUES (%s, %s,%s, %s, %s)\n",
        "\"\"\"\n",
        "registros = []\n",
        "for index, row in Order_payments_Incremental.iterrows():\n",
        "    registros.append( \n",
        "        (\n",
        "            row['order_id'], \n",
        "            row['payment_sequential'], \n",
        "            row['payment_type'], \n",
        "            row['payment_installments'],\n",
        "            row['payment_value']\n",
        "            ))\n",
        "\n",
        "cursor.executemany(sql, registros)\n",
        "conexion.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfApDLvZJRqP"
      },
      "source": [
        "Incremental load Order Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKpB9qdqJRqP"
      },
      "outputs": [],
      "source": [
        "sql = \"\"\"\n",
        "INSERT INTO ecommerceolist.Order_reviews\n",
        "(review_id, order_id, review_score, review_comment_title, review_comment_message, review_creation_date,review_answer_timestamp)\n",
        "VALUES ( %s, %s, %s, %s, %s, %s, %s )\n",
        "\"\"\"\n",
        "registros = []\n",
        "for index, row in Order_reviews_Incremental.iterrows():\n",
        "    registros.append( \n",
        "        (\n",
        "            row['review_id'], \n",
        "            row['order_id'], \n",
        "            row['review_score'], \n",
        "            row['review_comment_title'],\n",
        "            row['review_comment_message'],\n",
        "            row['review_creation_date'],\n",
        "            row['review_answer_timestamp']\n",
        "            ))\n",
        "\n",
        "cursor.executemany(sql, registros)\n",
        "conexion.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad7nqS3pJRqP"
      },
      "source": [
        "Incremental Load Orders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1TyIoxMJRqQ"
      },
      "outputs": [],
      "source": [
        "sql = \"\"\"\n",
        "INSERT INTO ecommerceolist.Orders(order_id, customer_id, order_status, order_purchase_timestamp, order_approved_at, order_delivered_carrier_date,order_delivered_customer_date,order_estimated_delivery_date) \n",
        "VALUES (%s, %s,%s, %s, %s, %s, %s, %s)\n",
        "\"\"\"\n",
        "registros = []\n",
        "for index, row in Orders_Incremental.iterrows():\n",
        "    registros.append( \n",
        "        (\n",
        "            row['order_id'], \n",
        "            row['customer_id'], \n",
        "            row['order_status'], \n",
        "            row['order_purchase_timestamp'],\n",
        "            row['order_approved_at'],\n",
        "            row['order_delivered_carrier_date'],\n",
        "            row['order_delivered_customer_date'],\n",
        "            row['order_estimated_delivery_date']\n",
        "            ))\n",
        "\n",
        "cursor.executemany(sql, registros)\n",
        "conexion.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhI8B7XwJRqQ"
      },
      "source": [
        "Incremental load Products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egNFeEsXJRqR"
      },
      "outputs": [],
      "source": [
        "sql = \"\"\"\n",
        "INSERT INTO ecommerceolist.Products(product_id, product_category_name, product_name_lenght, product_description_lenght, product_photos_qty, product_weight_g,product_length_cm,product_height_cm,product_width_cm) \n",
        "VALUES (%s, %s,%s, %s, %s, %s, %s, %s, %s)\n",
        "\"\"\"\n",
        "registros = []\n",
        "for index, row in Products_Incremental.iterrows():\n",
        "    registros.append( \n",
        "        (\n",
        "            row['product_id'], \n",
        "            row['product_category_name'], \n",
        "            row['product_name_lenght'], \n",
        "            row['product_description_lenght'],\n",
        "            row['product_photos_qty'],\n",
        "            row['product_weight_g'],\n",
        "            row['product_length_cm'],\n",
        "            row['product_height_cm'],\n",
        "            row['product_width_cm']\n",
        "            ))\n",
        "\n",
        "cursor.executemany(sql, registros)\n",
        "conexion.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc6k3uTcJRqR"
      },
      "source": [
        "Incremental load Sellers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIBtBJG0JRqR"
      },
      "outputs": [],
      "source": [
        "sql = \"\"\"\n",
        "INSERT INTO ecommerceolist.Sellers(seller_id, seller_zip_code_prefix, seller_city, seller_state) \n",
        "VALUES (%s, %s,%s, %s)\n",
        "\"\"\"\n",
        "registros = []\n",
        "for index, row in Sellers_Incremental.iterrows():\n",
        "    registros.append( \n",
        "        (\n",
        "            row['seller_id'], \n",
        "            row['seller_zip_code_prefix'], \n",
        "            row['seller_city'], \n",
        "            row['seller_state']\n",
        "            ))\n",
        "\n",
        "cursor.executemany(sql, registros)\n",
        "conexion.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqsbIelKJRqR"
      },
      "source": [
        "Incremental load Category translat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4mpaM17JRqS"
      },
      "outputs": [],
      "source": [
        "sql = \"\"\"\n",
        "INSERT INTO ecommerceolist.Category_translat(product_category_name, product_category_name_english) \n",
        "VALUES (%s, %s)\n",
        "\"\"\"\n",
        "registros = []\n",
        "for index, row in Category_translat_Incremental.iterrows():\n",
        "    registros.append( \n",
        "        (\n",
        "            row['product_category_name'], \n",
        "            row['product_category_name_english']\n",
        "            ))\n",
        "\n",
        "cursor.executemany(sql, registros)\n",
        "conexion.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGSWxc1oJRqS"
      },
      "source": [
        "This completes our ETL process."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}